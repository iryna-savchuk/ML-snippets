{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"e84c585c-a662-46b6-bc7d-951f3af0d491","showTitle":false,"title":""}},"source":["# Creating a Churn prediction model\n","\n","This notebook covers the following steps:\n","- Creating ML Pipeline using PySpark MlLib\n","- Tuning the hyperparameters of the model using PySpark\n","- Tracking the tuning experiments using MlFlow"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"1b4bb03d-54e2-4481-8fe3-fe92b9b6d554","showTitle":false,"title":""}},"outputs":[],"source":["spark.sparkContext.setLogLevel(\"WARN\")\n","\n","#The setLogLevel method is used to set the logging level for Spark. \n","# Spark will only display warning messages or higher severity messages in the console or logs, \n","# which can be helpful in reducing the amount of output and improving performance. \n","# \n","# Setting the logging level to WARN can be especially useful in a production environment."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"4ef00cdc-9c4a-4d92-b2dc-fc49f5b084de","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["Python interpreter will be restarted.\n","Collecting mlflow\n","  Downloading mlflow-2.3.2-py3-none-any.whl (17.7 MB)\n","Collecting gunicorn<21\n","  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n","Collecting docker<7,>=4.0.0\n","  Downloading docker-6.1.2-py3-none-any.whl (148 kB)\n","Requirement already satisfied: pytz<2024 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (2021.3)\n","Collecting pyyaml<7,>=5.1\n","  Downloading PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\n","Requirement already satisfied: pyarrow<12,>=4.0.0 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (7.0.0)\n","Collecting gitpython<4,>=2.1.0\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","Collecting cloudpickle<3\n","  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n","Requirement already satisfied: protobuf<5,>=3.12.0 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (3.19.4)\n","Requirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (2.27.1)\n","Requirement already satisfied: numpy<2 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (1.21.5)\n","Collecting alembic!=1.10.0,<2\n","  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n","Requirement already satisfied: Jinja2<4,>=2.11 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (2.11.3)\n","Requirement already satisfied: scipy<2 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (1.7.3)\n","Collecting Flask<3\n","  Downloading Flask-2.3.2-py3-none-any.whl (96 kB)\n","Requirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (3.5.1)\n","Requirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (1.0.2)\n","Requirement already satisfied: entrypoints<1 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (0.4)\n","Collecting markdown<4,>=3.3\n","  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n","Requirement already satisfied: pandas<3 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (1.4.2)\n","Collecting querystring-parser<2\n","  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n","Collecting importlib-metadata!=4.7.0,<7,>=3.7.0\n","  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n","Collecting sqlalchemy<3,>=1.4.0\n","  Downloading SQLAlchemy-2.0.15-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n","Requirement already satisfied: packaging<24 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (21.3)\n","Collecting sqlparse<1,>=0.4.0\n","  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n","Collecting databricks-cli<1,>=0.8.7\n","  Downloading databricks-cli-0.17.7.tar.gz (83 kB)\n","Requirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (8.0.4)\n","Collecting Mako\n","  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n","Requirement already satisfied: typing-extensions>=4 in /databricks/python3/lib/python3.9/site-packages (from alembic!=1.10.0,<2->mlflow) (4.1.1)\n","Collecting pyjwt>=1.7.0\n","  Downloading PyJWT-2.7.0-py3-none-any.whl (22 kB)\n","Collecting oauthlib>=3.1.0\n","  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n","Collecting tabulate>=0.7.7\n","  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n","Requirement already satisfied: six>=1.10.0 in /databricks/python3/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n","Requirement already satisfied: urllib3<2.0.0,>=1.26.7 in /databricks/python3/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.26.9)\n","Collecting websocket-client>=0.32.0\n","  Downloading websocket_client-1.5.2-py3-none-any.whl (56 kB)\n","Collecting Werkzeug>=2.3.3\n","  Downloading Werkzeug-2.3.4-py3-none-any.whl (242 kB)\n","Collecting click<9,>=7.0\n","  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n","Collecting itsdangerous>=2.1.2\n","  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n","Collecting blinker>=1.6.2\n","  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n","Collecting Jinja2<4,>=2.11\n","  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: setuptools>=3.0 in /databricks/python3/lib/python3.9/site-packages (from gunicorn<21->mlflow) (61.2.0)\n","Collecting zipp>=0.5\n","  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.9/site-packages (from Jinja2<4,>=2.11->mlflow) (2.0.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (2.8.2)\n","Requirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (4.25.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (1.3.2)\n","Requirement already satisfied: pyparsing>=2.2.1 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (3.0.4)\n","Requirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (0.11.0)\n","Requirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (9.0.1)\n","Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (3.3)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (2021.10.8)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from scikit-learn<2->mlflow) (2.2.0)\n","Requirement already satisfied: joblib>=0.11 in /databricks/python3/lib/python3.9/site-packages (from scikit-learn<2->mlflow) (1.1.1)\n","Collecting typing-extensions>=4\n","  Downloading typing_extensions-4.6.0-py3-none-any.whl (30 kB)\n","Collecting greenlet!=0.4.17\n","  Downloading greenlet-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (610 kB)\n","Collecting MarkupSafe>=2.0\n","  Downloading MarkupSafe-2.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n","Building wheels for collected packages: databricks-cli\n","  Building wheel for databricks-cli (setup.py): started\n","  Building wheel for databricks-cli (setup.py): finished with status 'done'\n","  Created wheel for databricks-cli: filename=databricks_cli-0.17.7-py3-none-any.whl size=143878 sha256=a43b3dc688f290dd368df80b3eda7fff64887dbb4d246ba93d36b2e186096342\n","  Stored in directory: /root/.cache/pip/wheels/b6/90/68/94d223a35a3910c1512a8d42d9f8333ce567ef26e250a56227\n","Successfully built databricks-cli\n","Installing collected packages: zipp, typing-extensions, smmap, MarkupSafe, greenlet, Werkzeug, websocket-client, tabulate, sqlalchemy, pyjwt, oauthlib, Mako, Jinja2, itsdangerous, importlib-metadata, gitdb, click, blinker, sqlparse, querystring-parser, pyyaml, markdown, gunicorn, gitpython, Flask, docker, databricks-cli, cloudpickle, alembic, mlflow\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing-extensions 4.1.1\n","    Not uninstalling typing-extensions at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-056461b7-fd8d-4b2e-88ac-aad0c1e4dfde\n","    Can't uninstall 'typing-extensions'. No files were found to uninstall.\n","  Attempting uninstall: MarkupSafe\n","    Found existing installation: MarkupSafe 2.0.1\n","    Not uninstalling markupsafe at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-056461b7-fd8d-4b2e-88ac-aad0c1e4dfde\n","    Can't uninstall 'MarkupSafe'. No files were found to uninstall.\n","  Attempting uninstall: Jinja2\n","    Found existing installation: Jinja2 2.11.3\n","    Not uninstalling jinja2 at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-056461b7-fd8d-4b2e-88ac-aad0c1e4dfde\n","    Can't uninstall 'Jinja2'. No files were found to uninstall.\n","  Attempting uninstall: click\n","    Found existing installation: click 8.0.4\n","    Not uninstalling click at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-056461b7-fd8d-4b2e-88ac-aad0c1e4dfde\n","    Can't uninstall 'click'. No files were found to uninstall.\n","Successfully installed Flask-2.3.2 Jinja2-3.1.2 Mako-1.2.4 MarkupSafe-2.1.2 Werkzeug-2.3.4 alembic-1.11.1 blinker-1.6.2 click-8.1.3 cloudpickle-2.2.1 databricks-cli-0.17.7 docker-6.1.2 gitdb-4.0.10 gitpython-3.1.31 greenlet-2.0.2 gunicorn-20.1.0 importlib-metadata-6.6.0 itsdangerous-2.1.2 markdown-3.4.3 mlflow-2.3.2 oauthlib-3.2.2 pyjwt-2.7.0 pyyaml-6.0 querystring-parser-1.2.4 smmap-5.0.0 sqlalchemy-2.0.15 sqlparse-0.4.4 tabulate-0.9.0 typing-extensions-4.6.0 websocket-client-1.5.2 zipp-3.15.0\n","Python interpreter will be restarted.\n"]}],"source":["pip install mlflow"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"a9eaa448-60ff-4756-a0ed-a4d9e175ee04","showTitle":false,"title":""}},"source":["#### `Step 1`: Understanding Churn Modelling"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"2d063966-fbb0-40bd-8e17-eef302ef4aca","showTitle":false,"title":""}},"source":["Churn, in the context of business, refers to the phenomenon of customers or users ceasing their engagement or relationship with a company's product or service. It is commonly used to describe situations where customers discontinue using a service, cancel a subscription, or switch to a competitor. Churn can have a significant impact on a business, and modeling churn can help companies understand and mitigate this impact effectively.\n","\n","Modeling churn is essential for several reasons. **Firstly**, by identifying the factors that contribute to churn, companies can gain insights into customer behavior and preferences, allowing them to take proactive measures to retain customers. Understanding why customers churn can help businesses address their pain points, improve customer satisfaction, and enhance overall service quality.\n","\n","**Secondly**, predicting churn enables businesses to allocate their resources effectively. By identifying customers who are likely to churn in the future, companies can prioritize retention efforts and allocate resources to targeted marketing campaigns, personalized offers, or tailored customer service interventions. This approach can be more cost-effective than applying retention strategies uniformly to all customers.\n","\n","**Lastly**, churn modeling helps companies evaluate the success of their retention strategies and make data-driven decisions. By tracking and analyzing churn rates over time, businesses can assess the effectiveness of their initiatives and optimize their retention efforts. This iterative process allows organizations to refine their strategies, test new interventions, and continuously improve customer retention rates.\n","\n","Let's consider a business example to illustrate the importance of churn modeling. Imagine you're working for a subscription-based streaming platform like Netflix. Churn modeling would be crucial for such a company because subscriber retention is vital for its success.\n","\n","By building a churn model, you could analyze various customer attributes and behaviors that contribute to churn. For instance, you might find that customers who have not engaged with the platform for a specific period or who consistently rate content poorly are more likely to churn. Armed with this knowledge, you can develop targeted retention strategies.\n","\n","Using the churn model predictions, you could implement personalized approaches to retain customers. For instance, if the model indicates that a particular subscriber is at high risk of churning, you could offer them a discounted subscription plan, recommend content tailored to their preferences, or send them personalized emails highlighting new releases aligned with their interests. These efforts can significantly improve customer retention rates and ultimately boost the platform's revenue and growth.\n","\n","Learn more [here](https://inmoment.com/blog/ready-to-tackle-customer-churn-heres-how/).\n","\n","![churn](https://inmoment.com/wp-content/uploads/2021/05/Customer-Churn-Rate.png)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"5ce82cb9-5350-40f4-bfb4-6db350621978","showTitle":false,"title":""}},"source":["#### `Step 2`: Load the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"7d3e2acb-b2cd-4379-8e8d-7745fc605aeb","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .table-result-container {\n","    max-height: 300px;\n","    overflow: auto;\n","  }\n","  table, th, td {\n","    border: 1px solid black;\n","    border-collapse: collapse;\n","  }\n","  th, td {\n","    padding: 5px;\n","  }\n","  th {\n","    text-align: left;\n","  }\n","</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>order_id</th><th>account_id</th><th>reference_date</th><th>merchant_id</th><th>order_shift</th><th>order_origin</th><th>delivery_fee</th><th>order_total</th><th>subsidy</th><th>device_app_version</th><th>city</th><th>merchant_category</th><th>distance_merchant_customer</th><th>nps_score</th><th>review_score</th><th>review_created_at</th><th>review_is_commented</th><th>review_is_fraud</th></tr></thead><tbody><tr><td>8c37df7a47f7acb958ba64a21d0b8c4615b520b725cd7c25d173aef79e9c8203</td><td>152569bd4e43dc5a773a60af1e871c669ea3df11773c57a3c9f15e6a612314e5</td><td>2021-06-05</td><td>bebf7f3a9f0d78e5f4e54a0236434ea3bd03d322b1796e2a93378dc2914d7057</td><td>weekend dinner</td><td>RESTAURANT</td><td>279.65000000000003</td><td>5459.650000000001</td><td>0.0</td><td>9.100.0</td><td>GONDOR</td><td>SMALL_BUSINESS</td><td>3447.1948</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>32611db6cd360ca4860bf334c4fb21f7f62009fb3bf3df07f1d46298e539e98e</td><td>6deb32d01419c424d4c95dfc95cebfb4fb0402384127817a4788a5d74545822b</td><td>2021-03-13</td><td>16d86434ef63db1a7a091648e87f57e701b94cef62a5b5b9b2060eefa0427bb7</td><td>weekend snack</td><td>RESTAURANT</td><td>367.15000000000003</td><td>3692.1499999999996</td><td>0.0</td><td>9.90.0</td><td>RIVENDELL</td><td>GOLD_PARTNER</td><td>8300.169</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>467fb17648c52ad77bfe2498b1c56729b89a0075b9315ee9d31581b741f5a00f</td><td>818d68c1fca75470a22de84a2824b889ced6d0defacc358b1a811711c0ca3574</td><td>2021-06-25</td><td>1d75761dcab70c44fcebf53f87c4b054d8d3f903648dd16cb9860b8baf601520</td><td>weekend dinner</td><td>RESTAURANT</td><td>0.0</td><td>7376.25</td><td>0.0</td><td>9.108.0</td><td>ROHAN</td><td>SMALL_BUSINESS</td><td>1432.896</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>80978f17425463a185f10630c65facec07a450bfa14f9b529a7ed127242cf5ab</td><td>22b830f42c585f4816bf7514ccf7d808b6be08985594557141150a99ae83bd8e</td><td>2021-01-28</td><td>9a1d8d7169dc1b2147154a335e8f3ca92b6e8ef70791e2ecec59f506676c4ba7</td><td>weekday dinner</td><td>RESTAURANT</td><td>280.0</td><td>1186.5</td><td>324.0</td><td>9.85.1</td><td>GONDOR</td><td>GOLD_PARTNER</td><td>7362.216</td><td>10</td><td>5.0</td><td>2021-01-30T02:43:44.330+0000</td><td>false</td><td>false</td></tr><tr><td>73c78c97246c5d3289934642ae6e673d07d64b79b6f1768095aaf93ebbe219ce</td><td>980c66024ef4d90a55ebd71348c824ddb5b998a463ac10d8da93b6dd1bc281d2</td><td>2021-03-03</td><td>17f056e61a4d0e43b36ff720deb3570aa6470660bf05ee018602bf89677cdb8a</td><td>weekday dinner</td><td>RESTAURANT</td><td>279.65000000000003</td><td>3170.65</td><td>0.0</td><td>9.90.0</td><td>GONDOR</td><td>GOLD_PARTNER</td><td>4926.0703</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"aggData":[],"aggError":"","aggOverflow":false,"aggSchema":[],"aggSeriesLimitReached":false,"aggType":"","arguments":{},"columnCustomDisplayInfos":{},"data":[["8c37df7a47f7acb958ba64a21d0b8c4615b520b725cd7c25d173aef79e9c8203","152569bd4e43dc5a773a60af1e871c669ea3df11773c57a3c9f15e6a612314e5","2021-06-05","bebf7f3a9f0d78e5f4e54a0236434ea3bd03d322b1796e2a93378dc2914d7057","weekend dinner","RESTAURANT",279.65000000000003,5459.650000000001,0,"9.100.0","GONDOR","SMALL_BUSINESS",3447.1948,null,null,null,null,null],["32611db6cd360ca4860bf334c4fb21f7f62009fb3bf3df07f1d46298e539e98e","6deb32d01419c424d4c95dfc95cebfb4fb0402384127817a4788a5d74545822b","2021-03-13","16d86434ef63db1a7a091648e87f57e701b94cef62a5b5b9b2060eefa0427bb7","weekend snack","RESTAURANT",367.15000000000003,3692.1499999999996,0,"9.90.0","RIVENDELL","GOLD_PARTNER",8300.169,null,null,null,null,null],["467fb17648c52ad77bfe2498b1c56729b89a0075b9315ee9d31581b741f5a00f","818d68c1fca75470a22de84a2824b889ced6d0defacc358b1a811711c0ca3574","2021-06-25","1d75761dcab70c44fcebf53f87c4b054d8d3f903648dd16cb9860b8baf601520","weekend dinner","RESTAURANT",0,7376.25,0,"9.108.0","ROHAN","SMALL_BUSINESS",1432.896,null,null,null,null,null],["80978f17425463a185f10630c65facec07a450bfa14f9b529a7ed127242cf5ab","22b830f42c585f4816bf7514ccf7d808b6be08985594557141150a99ae83bd8e","2021-01-28","9a1d8d7169dc1b2147154a335e8f3ca92b6e8ef70791e2ecec59f506676c4ba7","weekday dinner","RESTAURANT",280,1186.5,324,"9.85.1","GONDOR","GOLD_PARTNER",7362.216,"10",5,"2021-01-30T02:43:44.330+0000",false,false],["73c78c97246c5d3289934642ae6e673d07d64b79b6f1768095aaf93ebbe219ce","980c66024ef4d90a55ebd71348c824ddb5b998a463ac10d8da93b6dd1bc281d2","2021-03-03","17f056e61a4d0e43b36ff720deb3570aa6470660bf05ee018602bf89677cdb8a","weekday dinner","RESTAURANT",279.65000000000003,3170.65,0,"9.90.0","GONDOR","GOLD_PARTNER",4926.0703,null,null,null,null,null]],"datasetInfos":[],"dbfsResultPath":null,"isJsonSchema":true,"metadata":{},"overflow":false,"plotOptions":{"customPlotOptions":{},"displayType":"table","pivotAggregation":null,"pivotColumns":null,"xColumns":null,"yColumns":null},"removedWidgets":[],"schema":[{"metadata":"{}","name":"order_id","type":"\"string\""},{"metadata":"{}","name":"account_id","type":"\"string\""},{"metadata":"{}","name":"reference_date","type":"\"string\""},{"metadata":"{}","name":"merchant_id","type":"\"string\""},{"metadata":"{}","name":"order_shift","type":"\"string\""},{"metadata":"{}","name":"order_origin","type":"\"string\""},{"metadata":"{}","name":"delivery_fee","type":"\"double\""},{"metadata":"{}","name":"order_total","type":"\"double\""},{"metadata":"{}","name":"subsidy","type":"\"double\""},{"metadata":"{}","name":"device_app_version","type":"\"string\""},{"metadata":"{}","name":"city","type":"\"string\""},{"metadata":"{}","name":"merchant_category","type":"\"string\""},{"metadata":"{}","name":"distance_merchant_customer","type":"\"float\""},{"metadata":"{}","name":"nps_score","type":"\"string\""},{"metadata":"{}","name":"review_score","type":"\"double\""},{"metadata":"{}","name":"review_created_at","type":"\"timestamp\""},{"metadata":"{}","name":"review_is_commented","type":"\"boolean\""},{"metadata":"{}","name":"review_is_fraud","type":"\"boolean\""}],"type":"table"}},"output_type":"display_data"}],"source":["orders_df = spark.read.format(\"parquet\").option(\"header\",\"true\").load(\"/FileStore/bda_data/ord_sample/\")\n","\n","orders_df.limit(5).display()"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"3322a82f-b1f1-4663-95b1-8aca108f9fc4","showTitle":false,"title":""}},"source":["#### `Step 3`: Create the features and labels"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"a4b6f7d2-63b4-42db-9d25-c233f2a071b7","showTitle":false,"title":""}},"source":["The code below generate features from an input `DataFrame`, which contains information about orders made by different accounts. The features generated are based on the RFM (Recency, Frequency, Monetary) framework, with an additional categorical feature called `subsidy_bucket``."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"952aa3f3-3bc0-4d3e-b17b-3966af2c49db","showTitle":false,"title":""}},"outputs":[],"source":["from pyspark.sql import functions as f\n","from pyspark.sql.dataframe import DataFrame\n","\n","def generate_features(input_df: DataFrame, start_date: str, end_date:str, recency_reference_date: str) -> DataFrame:\n","    \"\"\"\n","    Generate RFM-based features and an additional categorical feature from the input DataFrame.\n","    \n","    :param input_df: Input DataFrame containing order information.\n","    :param start_date: Start date for filtering the input DataFrame.\n","    :param end_date: End date for filtering the input DataFrame.\n","    :param recency_reference_date: Reference date for calculating recency.\n","    :return: DataFrame with generated features.\n","    \"\"\"\n","    features_df = (\n","        input_df\n","        .filter(f.col('reference_date')>= start_date) #Filters the input DataFrame based on the start_date and end_date values.\n","        .filter(f.col('reference_date')< end_date)\n","        .groupBy('account_id') #Groups the filtered DataFrame by the 'account_id' column.\n","        .agg(\n","            f.countDistinct('order_id').alias('freq_3mo'),\n","            f.sum('order_total').alias('total_paid_3mo'),\n","            f.max('reference_date').alias('most_recent_order_date'),\n","            (f.sum('subsidy')/f.sum('order_total')).alias('subsidy_pct')\n","        ) #Aggregates the grouped DataFrame by performing various calculations\n","        .withColumn('recency', f.datediff(f.lit(recency_reference_date), f.col('most_recent_order_date')))\n","        # We will create this \"extra\" feature which is not in the RFM framework, just to work with categorical variables in our pipeline\n","        .withColumn(\n","            'subsidy_bucket', \n","            f.when(f.col('subsidy_pct') < 0.10, \"bucket_1\")\n","             .when(f.col('subsidy_pct') < 0.20, \"bucket_2\")\n","             .when(f.col('subsidy_pct') < 0.50, \"bucket_3\")\n","             .otherwise(\"bucket_4\") #Creates an additional categorical feature called 'subsidy_bucket' based on the 'subsidy_pct' value\n","        )\n","        .dropna(how='all')\n","        .drop(f.col('most_recent_order_date'), f.col('subsidy_pct')) #Drops any rows that contain all null values and drops the 'most_recent_order_date' and 'subsidy_pct' columns.\n","    )\n","    \n","    return features_df"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"f072fcd4-93c1-457c-afe7-ed83da2baf63","showTitle":false,"title":""}},"source":["The code below generate labels regarding the `churn` behavior of customers, from the input `DataFrame`.  \n","For that, we create a new column called `y_status` based on the activity of the accounts in comparing the period of two months. We filter only active users in the previous month and then:\n","   - If the account has no orders in the most recent month, assign a value of 1.\n","   - Otherwise, assign a value of 0.  \n","   \n"," The value of 1 represents `churned` customers;\n"," The value of 0 represents all the rest.  \n"," \n"," We encode our `y` as an integer because we need it in this format for the PySpark Ml Pipeline. Otherwise, we'd need to preprocess it, applying an `StringIndexer` to the categories."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"f1724012-239e-40d5-93c1-b904d606d6ed","showTitle":false,"title":""}},"outputs":[],"source":["from datetime import datetime, timedelta\n","\n","def generate_labels(input_df: DataFrame, y_month_string: str) -> DataFrame:\n","    \"\"\"\n","    Generate labels for the input DataFrame based on the activity of accounts in specific months.\n","    input_df should comprise at least 3 months of data, from the y_reference_month backwards\n","    \n","    :param input_df: Input DataFrame containing order information.\n","    :param y_reference_month: reference month for filtering the input DataFrame.\n","    \n","    :return: DataFrame with generated labels.\n","    \"\"\"\n","    y_month_date = datetime.strptime(y_month_string, '%Y-%m-%d')\n","    y_month_m1 = (y_month_date - timedelta(days=28)).replace(day=1) # truncate the date to month\n","\n","    # Format the modified date back to a string\n","    y_month_m1_string = y_month_m1.strftime('%Y-%m-%d')\n","\n","    labels_df = (\n","        orders_df\n","        .filter(f.col('reference_date')>= y_month_m1_string)\n","        .filter(f.col('reference_date')<= y_month_string)\n","        .withColumn('reference_month', f.date_trunc('month', f.col('reference_date')).cast('date'))\n","        .groupBy('account_id')\n","        .pivot('reference_month')\n","        .agg(\n","            f.countDistinct('order_id')\n","        )\n","        .filter(f.col(y_month_m1_string).isNotNull()) # only users active in last month\n","        .withColumn(\n","            'y_status',\n","            f.when(f.col(y_month_string).isNull(), 1).otherwise(0)\n","        )\n","        .select('account_id', 'y_status', f.col(y_month_m1_string).alias('orders_m-1'))\n","        .fillna(0, subset=['orders_m-1'])\n","\n","    )\n","    return labels_df"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"f0813c9c-1140-4bb0-b4e4-ee5db14138e5","showTitle":false,"title":""}},"source":["Now we encapsulate the feature and labels generation in one single function:"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"1c564c99-c2c8-47a2-ad9b-4d4d7117ce52","showTitle":false,"title":""}},"outputs":[],"source":["def generate_features_and_labels(input_df: DataFrame) -> DataFrame:\n","    features_df = input_df.transform(lambda df: generate_features(df, '2021-03-01', '2021-06-01', '2021-06-01'))\n","    labels_df = input_df.transform(lambda df: generate_labels(df, '2021-06-01'))\n","    output_df = labels_df.join(features_df, ['account_id'], 'inner')\n","    \n","    return output_df"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"cc79a35d-3166-4d96-9881-e6850965682d","showTitle":false,"title":""}},"source":["And then we apply it to our input data, also splitting the training and testing sets:"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"d57ec408-2cfc-4cf4-95c0-2e8a679a2fec","showTitle":false,"title":""}},"outputs":[],"source":["train_data, test_data = orders_df.transform(generate_features_and_labels).randomSplit([0.7, 0.3], seed=42)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"06fd3fcc-b333-44d5-9813-9481818e11b7","showTitle":false,"title":""}},"source":["#### `Step 4`: Train the pipeline"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"4c561dde-26b8-4fa9-bedc-8f14111ac7e9","showTitle":false,"title":""}},"source":["The code below creates a ML `Pipeline` for a classification problem. The pipeline consists of several preprocessing steps and a RandomForestClassifier mode. Here's a step-by-step explanation of the code:"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"8a8f25e2-8da6-47fb-8646-315ba804707e","showTitle":false,"title":""}},"outputs":[],"source":["# 1. Import the necessary classes and functions from PySpark's ML library.\n","from pyspark.ml.feature import Imputer, VectorAssembler, StringIndexer, OneHotEncoder, StandardScaler\n","from pyspark.ml.classification import RandomForestClassifier\n","from pyspark.ml import Pipeline, PipelineModel\n","\n","# 2. Create an Imputer to fill missing values in the 'freq_3mo', 'total_paid_3mo', and 'recency' columns.\n","impute = Imputer(inputCols=['freq_3mo', 'total_paid_3mo', 'recency'], outputCols=['freq_3mo', 'total_paid_3mo', 'recency']) \n","\n","# 3. Create a VectorAssembler to combine the continuous features into a single vector column called 'continuous_features'.\n","assemble = VectorAssembler(inputCols=['freq_3mo', 'total_paid_3mo', 'recency', 'orders_m-1'], outputCol='continuous_features')\n","\n","# 4. Create a StandardScaler to scale the continuous features to have zero mean and unit variance.\n","scale = StandardScaler(inputCol='continuous_features', outputCol='scaled_continuous_features', withMean=True, withStd=True)\n","\n","# 5. Create a StringIndexer to convert the 'subsidy_bucket' column into a numerical index column called 'subsidy_bucket_idx'.\n","index = StringIndexer(inputCols=['subsidy_bucket'], outputCols=['subsidy_bucket_idx'])\n","\n","# 6. Create a OneHotEncoder to convert the 'subsidy_bucket_idx' column into a one-hot encoded vector column called 'subsidy_bucket_vector'.\n","one_hot = OneHotEncoder(inputCol='subsidy_bucket_idx', outputCol='subsidy_bucket_vector')\n","\n","# 7. Create another VectorAssembler to combine the scaled continuous features and the one-hot encoded categorical feature into a single vector column called 'input_features'.\n","final_assemble = VectorAssembler(inputCols=['scaled_continuous_features', 'subsidy_bucket_vector'], outputCol='input_features')\n","\n","# 8. Create a RandomForestClassifier with the specified input and output columns.\n","rf = RandomForestClassifier(featuresCol=\"input_features\", labelCol=\"y_status\", predictionCol=\"prediction\")"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"c32bd197-a5f0-4cf6-b236-5273b2ecb5ca","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["Out[7]: Pipeline_184e4ffb1c2e"]}],"source":["# 9. Create a Pipeline and set its stages to include all the preprocessing steps and the classifier.\n","pipe = Pipeline()\n","pipe.setStages(\n","    [\n","        impute,\n","        assemble,\n","        scale,\n","        index,\n","        one_hot,\n","        final_assemble,\n","        rf\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"5a11ece7-fa02-4021-bd76-dee19817cc01","showTitle":false,"title":""}},"outputs":[],"source":["# 10. Fit the pipeline to the training data. (CMD may take 5 or more minutes)\n","pipe_model = pipe.fit(train_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 11. Save the fitted pipeline model to a specified path.\n","chkpt_path = 'dbfs:/FileStore/models_checkpoints/churn_classifier_1/'\n","pipe_model.save(chkpt_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"2a5af9f6-eb05-4984-835b-705d4237af17","showTitle":false,"title":""}},"outputs":[],"source":["# 12. Load the saved pipeline model.\n","pipe_model_loaded = PipelineModel.load(chkpt_path)\n","\n","\n","#13. Transform the training and test data using the loaded pipeline model.\n","fitted_train_data = pipe_model_loaded.transform(train_data)\n","fitted_test_data = pipe_model_loaded.transform(test_data)"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"1897915a-ce19-4584-b1c5-4f2ff102e72d","showTitle":false,"title":""}},"source":["#### `Step 5`: Evaluate classifier"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"53a0c22c-c8f0-41da-ba37-8e51b2170f36","showTitle":false,"title":""}},"source":["We can create a `confusion matrix`...\n","|                   | Predicted Negative | Predicted Positive |\n","|-------------------|--------------------|--------------------|\n","| **Actual Negative** |        True Neg          |        False Pos          |\n","| **Actual Positive** |        False Neg          |        True Pos          |\n","\n","...with a simple aggregation usin `.pivot()`:"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"8e3991f6-2a52-4456-bfc8-c29475357de7","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .table-result-container {\n","    max-height: 300px;\n","    overflow: auto;\n","  }\n","  table, th, td {\n","    border: 1px solid black;\n","    border-collapse: collapse;\n","  }\n","  th, td {\n","    padding: 5px;\n","  }\n","  th {\n","    text-align: left;\n","  }\n","</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>y_status</th><th>0.0</th><th>1.0</th></tr></thead><tbody><tr><td>1</td><td>790</td><td>17939</td></tr><tr><td>0</td><td>1379</td><td>4517</td></tr></tbody></table></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"aggData":[],"aggError":"","aggOverflow":false,"aggSchema":[],"aggSeriesLimitReached":false,"aggType":"","arguments":{},"columnCustomDisplayInfos":{},"data":[[1,790,17939],[0,1379,4517]],"datasetInfos":[],"dbfsResultPath":null,"isJsonSchema":true,"metadata":{},"overflow":false,"plotOptions":{"customPlotOptions":{},"displayType":"table","pivotAggregation":null,"pivotColumns":null,"xColumns":null,"yColumns":null},"removedWidgets":[],"schema":[{"metadata":"{}","name":"y_status","type":"\"integer\""},{"metadata":"{}","name":"0.0","type":"\"long\""},{"metadata":"{}","name":"1.0","type":"\"long\""}],"type":"table"}},"output_type":"display_data"}],"source":["fitted_train_data.groupBy('y_status').pivot('prediction').count().display()"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"b1d84342-611c-41cb-9179-3b250cbb23ac","showTitle":false,"title":""}},"source":["We can also use the `MulticlassClassificationEvaluator` from PySpark's ML library to evaluate the performance of a classification model on both the training and test datasets. The evaluation metric used in this case is the F1-Score."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"f5e1bb00-bd6c-43fd-9ef1-15d1d3179c7e","showTitle":false,"title":""}},"outputs":[],"source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","\n","# Create an evaluator instance with the specified label column, prediction column, and metric name (accuracy)\n","evaluator = MulticlassClassificationEvaluator(\n","    labelCol=\"y_status\", predictionCol=\"prediction\", metricName=\"f1\")\n","\n","# accepted metrics: f1|accuracy|weightedPrecision|weightedRecall|weightedTruePositiveRate| weightedFalsePositiveRate|weightedFMeasure|truePositiveRateByLabel| falsePositiveRateByLabel|precisionByLabel|recallByLabel|fMeasureByLabel| logLoss|hammingLoss"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"a12f0270-93a4-40ec-97c1-ec8bff7df6ac","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["Training F1-Score = 0.744442\n","Test F1-Score = 0.734919\n"]}],"source":["# Evaluate the f1-score of the model on the fitted training data\n","train_metric = evaluator.evaluate(fitted_train_data)\n","print(\"Training F1-Score = %g\" % train_metric)\n","\n","# Evaluate the f1-score of the model on the fitted test data\n","test_metric = evaluator.evaluate(fitted_test_data)\n","print(\"Test F1-Score = %g\" % test_metric)"]},{"attachments":{},"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"9efc1dd6-5544-44dd-bee4-2c5eb84bf4a6","showTitle":false,"title":""}},"source":["#### `Step 6`: Tune the model hyperparameters"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"cd089c4b-9126-4ce2-9502-022782000127","showTitle":false,"title":""}},"source":["Now we perform hyperparameter tuning for a `RandomForestClassifier` model using Ml Lib `TrainValidationSplit`. The goal is to find the best combination of hyperparameters that results in the highest model performance."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"2ac4c56c-cfe0-4524-b45c-d36c10663b00","showTitle":false,"title":""}},"outputs":[],"source":["#CMD may take up to 20 min\n","\n","from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, TrainValidationSplit\n","\n","# Define parameter grid to search over\n","paramGrid = (\n","    ParamGridBuilder()\n","    .addGrid(rf.numTrees, [10])\n","    .addGrid(rf.maxDepth, [2, 4])\n","    .addGrid(rf.maxBins, [4, 8])\n","    .build()\n",")\n","\n","# Define TrainValidationSplit with 75% of the data for training and 25% for validation\n","tvs = TrainValidationSplit(estimator=pipe, estimatorParamMaps=paramGrid, evaluator=evaluator, trainRatio=0.75)\n","\n","# Fit TrainValidationSplit to training data\n","tvsModel = tvs.fit(train_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"acfc0fdb-a0a9-415a-abb1-0efd1833e371","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["Out[15]: [0.6439457338153165,\n"," 0.6439457338153165,\n"," 0.7301348374305254,\n"," 0.7187422068901542]"]}],"source":["# Retrieve the validation metrics for each combination of hyperparameters.\n","tvsModel.validationMetrics"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"0ab01dad-ea1d-4c01-bb42-583fec35a3db","showTitle":false,"title":""}},"outputs":[],"source":["# Get the best model from the TrainValidationSplit instance.\n","best_model = tvsModel.bestModel"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"09d16725-f10d-438d-8a0c-27a0f6caad68","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["Out[17]: {'bootstrap': True,\n"," 'cacheNodeIds': False,\n"," 'checkpointInterval': 10,\n"," 'featureSubsetStrategy': 'auto',\n"," 'featuresCol': 'input_features',\n"," 'impurity': 'gini',\n"," 'labelCol': 'y_status',\n"," 'leafCol': '',\n"," 'maxBins': 4,\n"," 'maxDepth': 4,\n"," 'maxMemoryInMB': 256,\n"," 'minInfoGain': 0.0,\n"," 'minInstancesPerNode': 1,\n"," 'minWeightFractionPerNode': 0.0,\n"," 'numTrees': 10,\n"," 'predictionCol': 'prediction',\n"," 'probabilityCol': 'probability',\n"," 'rawPredictionCol': 'rawPrediction',\n"," 'seed': -5387697053847413545,\n"," 'subsamplingRate': 1.0}"]}],"source":["# Extract the RandomForestClassifier model from the best model's pipeline stages.\n","# stages is an attribute of best_model that represents the pipeline stages of the model.\n","# [-1] is an index that retrieves the last stage of the pipeline.\n","rf_model = best_model.stages[-1] \n","\n","#  A pipeline is a sequence of stages that are executed in a specific order to process and transform data. Each stage in the pipeline represents a data transformation or a machine learning algorithm. The last stage of the pipeline [-1] refers to the final stage in the sequence of stages defined in the pipeline. It is the stage that is executed last when processing data. In the given code, best_model.stages[-1] retrieves the last stage of the pipeline.\n","\n","# Get the model's parameters and create a dictionary mapping parameter names to values.\n","params = rf_model.extractParamMap()\n","param_names = [ k.name for k in params.keys() ]\n","param_values = [ v for v in params.values() ]\n","params_dict = dict(zip(param_names, param_values))\n","\n","params_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"2ebefbcd-7130-44cd-ac90-6c7b4fcd7837","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["Out[18]: 0.7340688060387152"]}],"source":["# Evaluate the best model on the test data using the evaluator.\n","evaluator.evaluate(best_model.transform(test_data))"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"48865084-f00f-461d-a35a-db853df03cda","showTitle":false,"title":""}},"source":["#### `Step 7`: Track experiments with ML Flow"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"c2d14845-46da-40c3-abb6-fd196bca0294","showTitle":false,"title":""}},"source":["The code below helps us find the best combination of hyperparameters for the RandomForestClassifier by performing a manual grid search and cross-validation. The results are logged using MLflow, which allows us to analyze and compare the performance of different models easily.\n","\n","MLflow is an open source platform for managing the end-to-end machine learning lifecycle. MLflow supports tracking for machine learning model tuning in Python, R, and Scala."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"852ec9e3-4cf1-45e2-982c-687e102db27e","showTitle":false,"title":""}},"outputs":[],"source":["!python3 -m pip freeze --disable-pip-version-check --exclude-editable --no-cache-dir > requirements.txt\n","\n","# python3 -m pip: Invokes the Python package installer (pip) associated with Python 3.\n","# freeze: The freeze command displays a list of installed packages and their versions.\n","# --disable-pip-version-check: Disables the check for the latest version of pip.\n","# --exclude-editable: Excludes packages installed in editable mode (editable installations are usually used for development purposes).\n","# --no-cache-dir: Skips caching when retrieving package metadata.\n","# > requirements.txt: Redirects the output of the pip freeze command to a file named requirements.txt.\n","# In summary, this code generates a file named requirements.txt containing a list of installed Python packages and their versions, which is commonly used for documenting project dependencies and facilitating reproducibility."]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"31180a2d-1ee3-40e3-be66-9510085c925e","showTitle":false,"title":""}},"source":["In order to have more control over mlflow logging, we will create a manual cross validation training loop.  \n","Let's start by defining the parameters grid and the cv folds:"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"9e568d51-575c-4e15-867b-a9bd1d6d3f0f","showTitle":false,"title":""}},"outputs":[{"data":{"application/vnd.databricks.v1+bamboolib_hint":"{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}","text/plain":[]},"metadata":{},"output_type":"display_data"}],"source":["from functools import reduce\n","import numpy as np\n","import pandas as pd\n","\n","# Define the parameter grid for maxDepth and numBins\n","max_depths = [2, 4, 8]\n","num_bins = [2, 4, 8]\n","\n","# Create a pandas DataFrame with the parameter combinations\n","param_grid = pd.DataFrame([(depth, bins) for depth in max_depths for bins in num_bins], columns=['max_depth', 'num_bins'])\n","\n","# Perform manual 3-fold cross-validation\n","num_folds = 3\n","probs = [0.33, 0.33, 0.33] \n","train_data_to_split = train_data.cache()\n","splits = train_data_to_split.randomSplit(probs, seed=42)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"641d08f9-53a8-4a87-b08a-37f772dac3c5","showTitle":false,"title":""}},"source":["Now we set the `mlflow` experiment.  \n","Experiments let you visualize, search for, and compare runs (each time the model is trained inside the tuning loop), as well as download run artifacts and metadata for analysis in other tools. An MLflow run corresponds to a single execution of model code. It's highly recommended to organize training runs with MLflow experiments."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"1f5deb92-a18a-4f71-8e22-1130686b238e","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["Out[21]: <Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/2402731393051134', creation_time=1684771975240, experiment_id='2402731393051134', last_update_time=1684805566017, lifecycle_stage='active', name='/Shared/manual_cv_rf_pipeline_2', tags={'mlflow.experiment.sourceName': '/Shared/manual_cv_rf_pipeline_2',\n"," 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n"," 'mlflow.ownerEmail': '50123@novasbe.pt',\n"," 'mlflow.ownerId': '3991991021770629'}>"]}],"source":["import mlflow\n","\n","experiment_name = \"/Shared/manual_cv_rf_pipeline_2\"\n","mlflow.set_experiment(experiment_name)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"276e6e0c-0634-4c17-a2c6-18ac937b20f3","showTitle":false,"title":""}},"source":["Now we go through the tuning loop:"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"ebd8fdbe-c81f-482f-a347-5fc5444d7210","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","java.io.IOException: Connection failed\n","\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:766)\n","\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:693)\n","\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n","\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:268)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:240)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:149)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:794)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:469)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:250)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:140)\n","\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n","\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1551)\n","\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:602)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:822)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:254)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1400(ManagedSelector.java:62)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:543)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:401)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$6(InstrumentedQueuedThreadPool.scala:136)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:73)\n","\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:70)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:102)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:131)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: java.net.ConnectException: Connection refused\n","\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n","\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n","\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:232)\n","\t... 17 more"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"java.io.IOException: Connection failed\n\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:766)\n\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:693)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:268)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:240)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:149)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:794)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:469)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:250)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:140)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1551)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:602)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:822)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:254)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1400(ManagedSelector.java:62)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:543)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:401)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$6(InstrumentedQueuedThreadPool.scala:136)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:73)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:70)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:102)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:131)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.net.ConnectException: Connection refused\n\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:232)\n\t... 17 more\n","errorSummary":"Internal error. Attach your notebook to a different cluster or restart the current cluster.","errorTraceType":null,"metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["with mlflow.start_run():\n","    active_run = mlflow.active_run()\n","    expId = active_run.info.experiment_id\n","    print(f\"Exp ID: {expId}\")\n","    \n","    for _, row in param_grid.iterrows():\n","        depth = row['max_depth']\n","        bins = row['num_bins']\n","        \n","        # Set the parameters for the RandomForestClassifier\n","        pipe.getStages()[-1].setParams(maxDepth=depth, maxBins=bins)\n","\n","        # Initialize the metrics for x-val\n","        metrics = []\n","\n","        # Log the parameters and evaluation metrics using MLflow\n","        with mlflow.start_run(nested=True): \n","            \n","            # Perform k-fold cross-validation\n","            for i in range(num_folds):\n","                # Split the data into training and test sets\n","                validation_df = splits[i]\n","                train_splits = splits.copy()\n","                train_splits.pop(i)\n","                train_df = reduce(lambda x,y: x.union(y), train_splits)\n","\n","                # Train the model\n","                model = pipe.fit(train_df)\n","\n","                # Make predictions on the test set\n","                predictions = model.transform(validation_df)\n","\n","                # Evaluate the model\n","                metric = evaluator.evaluate(predictions)\n","                metrics.append(metric)\n","            \n","            # Calculate the average accuracy across the folds\n","            avg_metric = np.mean(metrics)\n","        \n","            mlflow.log_param(\"max_depth\", depth)\n","            mlflow.log_param(\"num_bins\", bins)\n","            mlflow.log_metric(\"avg_accuracy\", avg_metric)\n","\n","            print(f\"MaxDepth: {depth}, NumBins: {bins}, avgMetric: {avg_metric}\")\n","            mlflow.spark.log_model(model, \"model\", pip_requirements=\"requirements.txt\") # passing the requirements speed up the log_model process\n","\n","train_data_to_split.unpersist()"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"5756ea88-9528-41b2-95a7-21ff18b8bd57","showTitle":false,"title":""}},"source":["**An important disclaimer:**\n","It's not recommended to run a manual parameter search like this. We performed it so you can understand how tracking experiments with `mlflow` works. There are very performatic framework that are integrated with mlflow logging, like `hyperopt` or `ray-tune`. If you want to tune your models like a pro, you should go for these frameworks."]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"cddd8900-d7e7-4296-94eb-f3aca68408ee","showTitle":false,"title":""}},"source":["To view the MLflow experiment associated with the notebook, click the **Experiment** icon in the notebook context bar on the upper right. All notebook runs appear in the sidebar. To more easily compare their results, click the icon at the far right of Experiment Runs (it shows \"View Experiment UI\" when you hover over it). The Experiment page appears.\n","\n","But you can also access experiments data programatically:"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"aa4b0acb-02a2-48e7-aa15-96e3b7864191","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","java.io.IOException: Connection failed\n","\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:766)\n","\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:693)\n","\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n","\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:268)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:240)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:149)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:794)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:469)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:250)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:140)\n","\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n","\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1551)\n","\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:602)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:822)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:254)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1400(ManagedSelector.java:62)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:543)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:401)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$6(InstrumentedQueuedThreadPool.scala:136)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:73)\n","\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:70)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:102)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:131)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: java.net.ConnectException: Connection refused\n","\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n","\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n","\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:232)\n","\t... 17 more"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"java.io.IOException: Connection failed\n\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:766)\n\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:693)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:268)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:240)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:149)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:794)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:469)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:250)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:140)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1551)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:602)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:822)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:254)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1400(ManagedSelector.java:62)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:543)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:401)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$6(InstrumentedQueuedThreadPool.scala:136)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:73)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:70)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:102)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:131)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.net.ConnectException: Connection refused\n\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:232)\n\t... 17 more\n","errorSummary":"Internal error. Attach your notebook to a different cluster or restart the current cluster.","errorTraceType":null,"metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["#Read data from an MLflow experiment using Apache Spark. The spark object represents the SparkSession, and expId is the ID of the MLflow experiment we want to load. The data is loaded into a DataFrame called metrics_df.\n","metrics_df = spark.read.format(\"mlflow-experiment\").load(expId)\n","\n","metrics_df = (\n","    metrics_df\n","    #The select operation is used to select specific columns from the DataFrame. We are extracting the following columns:\n","    #- tags['mlflow.runName'] is accessed using the col function (f.col()) and then aliased as 'run_name'.\n","    #- run_id column is renamed to 'run_id'.\n","    #- params.max_depth column is renamed to 'max_depth'.\n","    #- params.num_bins column is renamed to 'num_bins'.\n","    #- metrics.avg_accuracy column is renamed to 'f1'.\n","      .select(f.col('tags')['mlflow.runName'].alias('run_name'), f.col('run_id').alias('run_id'),f.col('params.max_depth').alias('max_depth'), f.col('params.num_bins').alias('num_bins'), f.col('metrics.avg_accuracy').alias('f1'))\n","    .filter(f.col('f1').isNotNull()) # filter out rows where the 'f1' column is null. This removes any rows where the 'f1' column does not have a value.\n",")\n","\n","display(metrics_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"5e34df4d-1099-42ac-a697-6ea023d7ae7f","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","java.io.IOException: Connection failed\n","\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:766)\n","\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:693)\n","\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n","\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:268)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:240)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:149)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:794)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:469)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:250)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:140)\n","\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n","\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1551)\n","\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:602)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:822)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:254)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1400(ManagedSelector.java:62)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:543)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:401)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$6(InstrumentedQueuedThreadPool.scala:136)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:73)\n","\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:70)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:102)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:131)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: java.net.ConnectException: Connection refused\n","\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n","\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n","\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:232)\n","\t... 17 more"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"java.io.IOException: Connection failed\n\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:766)\n\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:693)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:268)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:240)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:149)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:794)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:469)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:250)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:140)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1551)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:602)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:822)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:254)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1400(ManagedSelector.java:62)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:543)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:401)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$6(InstrumentedQueuedThreadPool.scala:136)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:73)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:70)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:102)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:131)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.net.ConnectException: Connection refused\n\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:232)\n\t... 17 more\n","errorSummary":"Internal error. Attach your notebook to a different cluster or restart the current cluster.","errorTraceType":null,"metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["# Inference after loading the logged model\n","\n","model_uri = \"runs:/{}/model\".format(run_id) \n","loaded_model = mlflow.spark.load_model(model_uri)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"4dabbc80-fb75-4dc9-873a-6f4e9f569baf","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","java.io.IOException: Connection failed\n","\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:766)\n","\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:693)\n","\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n","\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:268)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:240)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:149)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:794)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:469)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:250)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:140)\n","\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n","\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1551)\n","\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:602)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:822)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:254)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1400(ManagedSelector.java:62)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:543)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:401)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$6(InstrumentedQueuedThreadPool.scala:136)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:73)\n","\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:70)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:102)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:131)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: java.net.ConnectException: Connection refused\n","\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n","\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n","\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:232)\n","\t... 17 more"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"java.io.IOException: Connection failed\n\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:766)\n\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:693)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:268)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:240)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:149)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:794)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:469)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:250)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:140)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1551)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:602)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:822)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:254)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1400(ManagedSelector.java:62)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:543)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:401)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$6(InstrumentedQueuedThreadPool.scala:136)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:73)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:70)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:102)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:131)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.net.ConnectException: Connection refused\n\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:232)\n\t... 17 more\n","errorSummary":"Internal error. Attach your notebook to a different cluster or restart the current cluster.","errorTraceType":null,"metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["loaded_model"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"0c28078e-7176-4aea-9f4f-2a5397a3f84f","showTitle":false,"title":""}},"source":["#### `EXTRA`: Add custom transformers to the pipeline stages"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"d63b58fb-7b51-4f29-bc1a-7da75cbdaab4","showTitle":false,"title":""}},"source":["To add a custom transform to the pipeline stages in PySpark MLlib, you can define a Python function that performs the data manipulation you want to encapsulate. Then, you can wrap this function in a PySpark Transformer object and add it to the pipeline stages.  \n","\n","In the example below, custom_transform is a Python function that performs some data manipulation on a PySpark DataFrame, and CustomTransformer is a PySpark Transformer object that wraps this function. The Pipeline object is then created with the custom transformer and a VectorAssembler stage to create a feature vector. Finally, the pipeline is fit to some input data, and then applied to new data using the transform method."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"0df92055-aea3-4a64-b124-915f661ece19","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","java.io.IOException: Connection failed\n","\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:766)\n","\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:693)\n","\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n","\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:268)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:240)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:149)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:794)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:469)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:250)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:140)\n","\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n","\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1551)\n","\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:602)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:822)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:254)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1400(ManagedSelector.java:62)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:543)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:401)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$6(InstrumentedQueuedThreadPool.scala:136)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:73)\n","\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:70)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:102)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:131)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: java.net.ConnectException: Connection refused\n","\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n","\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n","\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:232)\n","\t... 17 more"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"java.io.IOException: Connection failed\n\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:766)\n\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:693)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:268)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:240)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:149)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:794)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:469)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:250)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:140)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1551)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:602)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:822)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:254)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1400(ManagedSelector.java:62)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:543)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:401)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$6(InstrumentedQueuedThreadPool.scala:136)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:73)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:70)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:102)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:131)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.net.ConnectException: Connection refused\n\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:232)\n\t... 17 more\n","errorSummary":"Internal error. Attach your notebook to a different cluster or restart the current cluster.","errorTraceType":null,"metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["from pyspark.ml import Pipeline, Transformer\n","\n","# Define a PySpark Transformer object that wraps the custom_transform function\n","class GenerateFeaturesAndLabels(Transformer):\n","    def __init__(self):\n","        super(GenerateFeaturesAndLabels, self).__init__()\n","\n","    def _transform(self, df):\n","        df = df.transform(generate_features_and_labels)\n","        return df\n","    \n","gen_feat_label = GenerateFeaturesAndLabels()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"2f94de22-8aae-4d3d-b9d6-33cdcafced23","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","java.io.IOException: Connection failed\n","\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:766)\n","\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:693)\n","\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n","\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:268)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:240)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:149)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:794)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:469)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:250)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:140)\n","\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n","\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1551)\n","\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:602)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:822)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:254)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1400(ManagedSelector.java:62)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:543)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:401)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$6(InstrumentedQueuedThreadPool.scala:136)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:73)\n","\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:70)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:102)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:131)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: java.net.ConnectException: Connection refused\n","\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n","\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n","\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:232)\n","\t... 17 more"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"java.io.IOException: Connection failed\n\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:766)\n\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:693)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:268)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:240)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:149)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:794)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:469)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:250)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:140)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1551)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:602)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:822)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:254)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1400(ManagedSelector.java:62)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:543)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:401)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$6(InstrumentedQueuedThreadPool.scala:136)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:73)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:70)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:102)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:131)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.net.ConnectException: Connection refused\n\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:232)\n\t... 17 more\n","errorSummary":"Internal error. Attach your notebook to a different cluster or restart the current cluster.","errorTraceType":null,"metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["pipe = Pipeline()\n","pipe.setStages(\n","    [\n","        gen_feat_label,\n","        impute,\n","        assemble,\n","        scale,\n","        index,\n","        one_hot,\n","        final_assemble,\n","        rf\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"8f40af8c-f84a-4ece-b751-a601a7f372a5","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","java.io.IOException: Connection failed\n","\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:766)\n","\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:693)\n","\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n","\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:268)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:240)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:149)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:794)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:469)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:250)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:140)\n","\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n","\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1551)\n","\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n","\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:602)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n","\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:822)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:254)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1400(ManagedSelector.java:62)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:543)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:401)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$6(InstrumentedQueuedThreadPool.scala:136)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:73)\n","\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:70)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:102)\n","\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:131)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)\n","\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: java.net.ConnectException: Connection refused\n","\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n","\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n","\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n","\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:232)\n","\t... 17 more"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"java.io.IOException: Connection failed\n\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:766)\n\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:693)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:268)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:240)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:149)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:794)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:469)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:250)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:140)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1551)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:602)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:822)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:254)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1400(ManagedSelector.java:62)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:543)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:401)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:360)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:184)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:388)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$6(InstrumentedQueuedThreadPool.scala:136)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:73)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:70)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:102)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:131)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:806)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:938)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.net.ConnectException: Connection refused\n\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:232)\n\t... 17 more\n","errorSummary":"Internal error. Attach your notebook to a different cluster or restart the current cluster.","errorTraceType":null,"metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["# Fit the pipeline to your input data\n","pipe_model = pipe.fit(orders_df)\n","\n","# Apply the pipeline to new data\n","fitted_train_data = pipe_model.transform(orders_df)\n","\n","fitted_train_data.display()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"485e4949-7c11-4621-bc4e-8f616a88f97e","showTitle":false,"title":""}},"outputs":[],"source":[]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":877124515501031,"dataframes":["_sqldf"]},"pythonIndentUnit":4},"notebookName":"Lab 13 - Complete ML Pipeline - Solution","widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
